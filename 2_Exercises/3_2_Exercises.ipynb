{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0eb5fd45",
      "metadata": {
        "id": "0eb5fd45"
      },
      "source": [
        "# Webscraping II"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e8a1122",
      "metadata": {
        "id": "8e8a1122"
      },
      "source": [
        "## Exercise 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4879993",
      "metadata": {
        "id": "a4879993"
      },
      "source": [
        "Use ``selenium`` to go to https://job-room.ch and search for jobs related to Python (you may first need to close the orange message asking employers to register). Fetch the source code of the page with the search results, and convert it to a ``BeautifulSoup`` object. Can you print out the number of jobs that were found?\n",
        "\n",
        "Hints:\n",
        " * You might need to tell Python to wait for a bit before retrieveing the source code of the page (otherwise it might not have loaded fast enough). This can be done using the ``sleep`` function in the ``time`` module (or using ``waits`` in selenium).\n",
        " * To find out how to ``find_element()`` what you are looking for, try right click + \"Inspect\" in your browser to find suitable ways (e.g. via the ``id`` or ``class`` attribute).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "28ed93cf",
      "metadata": {
        "id": "28ed93cf"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import requests\n",
        "import math\n",
        "import time\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service as ChromeService # Renamed Service to avoid conflict\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from selenium.webdriver.common.by import By # To find elements\n",
        "from selenium.webdriver.common.keys import Keys # For special keys (Enter, delete, down etc.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "ff532473",
      "metadata": {
        "id": "ff532473"
      },
      "outputs": [],
      "source": [
        "# Initialize browser session and go to https://www.job-room.ch\n",
        "# Automatically download and manage ChromeDriver\n",
        "# The Service object will use the path provided by ChromeDriverManager\n",
        "service = ChromeService(executable_path=ChromeDriverManager().install())\n",
        "\n",
        "# Pass the service object when creating the driver instance\n",
        "browser = webdriver.Chrome(service=service)\n",
        "\n",
        "browser.get('https://www.job-room.ch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "316c7204",
      "metadata": {
        "id": "316c7204"
      },
      "outputs": [],
      "source": [
        "# Close orange message (optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "97622229",
      "metadata": {
        "id": "97622229"
      },
      "outputs": [],
      "source": [
        "# Navigate to the second search field (Skills) and enter \"Python\"\n",
        "elem = browser.find_element(By.ID, 'alv-multi-typeahead-portal.job-ad.search.query-panel.keywords.placeholder-0')\n",
        "\n",
        "elem.send_keys('python')\n",
        "elem.send_keys(Keys.ENTER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "0c3a1e38",
      "metadata": {
        "id": "0c3a1e38"
      },
      "outputs": [],
      "source": [
        "# Click on search botton\n",
        "elem = browser.find_element(By.CSS_SELECTOR, 'button[type = \"submit\"]')\n",
        "elem.click()\n",
        "time.sleep(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "f6d106fc",
      "metadata": {
        "id": "f6d106fc"
      },
      "outputs": [],
      "source": [
        "# Fetch source code and parse it with Beautiful soup\n",
        "source = browser.page_source\n",
        "\n",
        "soup = BeautifulSoup(source)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "8a79b26d",
      "metadata": {
        "id": "8a79b26d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'403'"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Print number of jobs\n",
        "n_jobs = soup.select(\"span[data-test='resultCount']\")[0].text\n",
        "n_jobs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f77b85ff",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "483f7cc6",
      "metadata": {
        "id": "483f7cc6"
      },
      "source": [
        "## Exercise 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c690606b",
      "metadata": {
        "id": "c690606b"
      },
      "source": [
        "Try to extract all the links to the pages on the indiviual jobs and store them in a list. How many links do you get?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "42193e18",
      "metadata": {
        "id": "42193e18"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "job_pages = [a[\"href\"] for a in soup.select(\".d-block.result-list-item\")]\n",
        "len(job_pages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57269d45",
      "metadata": {
        "id": "57269d45"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "7d2b7a1e",
      "metadata": {
        "id": "7d2b7a1e"
      },
      "source": [
        "## Exercise 3 (advanced and optional!)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f782062b",
      "metadata": {
        "id": "f782062b"
      },
      "source": [
        "You may have noticed that the you only got the urls for the first 20 search results. This happens because the other results are not rendered immediately, but only when you scroll down. Can you find a way to extract all the urls?\n",
        "\n",
        "Hint: You can tell the browser to scroll down until the end of the page is reached and then retrieve the source code. One approach would be to ``find_element()`` an element that resides within the scrollable container and then sending a couple ``Keys.PAGE.DOWN`` (but there might also be other ways)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "9aa3a07b",
      "metadata": {
        "id": "9aa3a07b"
      },
      "outputs": [],
      "source": [
        "n_jobs = int(n_jobs)\n",
        "job_per_scroll = 20\n",
        "\n",
        "# how many times do we have to scroll to show all the jobs?\n",
        "n_scrolls = math.ceil(n_jobs / job_per_scroll)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "5b5d1a69",
      "metadata": {
        "id": "5b5d1a69"
      },
      "outputs": [],
      "source": [
        "scrollable = browser.find_element(By.CLASS_NAME, \"container-fluid.ng-star-inserted\")\n",
        "\n",
        "for i in range(n_scrolls):\n",
        "    browser.execute_script(\"arguments[0].scrollTop = arguments[0].scrollTop + arguments[0].offsetHeight;\", scrollable)\n",
        "    time.sleep(0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af26cd87",
      "metadata": {
        "id": "af26cd87"
      },
      "source": [
        "Now, navigate to and fetch the source code of **one single url** of your list (we want to avoid that we do too many request with our course). Again, you might have to introduce a waiting time between loading the page and fetching the source code.  Print out (1) the title and (2) the workload of the job."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6d38e67",
      "metadata": {
        "id": "e6d38e67"
      },
      "outputs": [],
      "source": [
        "# Fetch page and convert to BeautifulSoup object\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e13ffea",
      "metadata": {
        "id": "5e13ffea"
      },
      "outputs": [],
      "source": [
        "# Print job title\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc9235c2",
      "metadata": {
        "id": "cc9235c2"
      },
      "outputs": [],
      "source": [
        "# Print workload\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
